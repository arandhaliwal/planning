Notes:

Tests on regular outcomes not very useful due to imbalance of db

Natural error due to fact that this isnt complete info - only proposal/constraints

Tests (300 cases in general):





AACBR, reg outcomes:


Normal test on whole casebase each time: 80% accuracy - but worse than 88% rate if you chose all approved (zero rule) as 264/300 approvals. (better than random at 50%? unsure)
P = 264
N = 36
True positives: 229
False positives = 25
True negatives = 11
False negatives = 35

Precision (PPV) = 0.901
NPV = 0.293
Recall (TPR) = 0.867
TNR = 0.305

F1 = 0.884

Temporally ordered test: 70 fails out of 300 - 77% accuracy
P = 264
N = 36
TP = 222
FP = 28
TN = 8
FN = 42

Precision (PPV) = 0.888
NPV = 0.16
Recall (TPR) = 0.841
TNR = 0.222

F1 = 0.817

> Slightly better results with whole cb available - implies better with more information

Not useful to look at local accuracy because of imbalanced casebase and lots of approvals at start? (areas with many approvals tend to have higher success rate)
Local success rates (each 50 tests)
1. 88%
2. 78%
3. 68%
4. 76%
5. 82%
6. 68%
-> no improvement, seemingly random / determined by location of approvals due to imbalanced dataset.







AACBR with factors as outcomes:


Test with whole casebase (294 cases):

Accuracy = 81% - compared to a best case of 57% using zero rule on negatives - big improvement

P = 127
N = 167
TP = 82
FP = 11
TN = 156
FN = 45

Precision (PPV) = 0.882
NPV = 0.776
Recall (TPR) = 0.646
TNR = 0.935

F1 = 0.746

Test with temporal ordering, using only previous cases each time:

Accuracy = 81%

P = 127
N = 167
TP = 81
FP = 11
TN = 156
FN = 46

Precision (PPV) = 0.880
NPV = 0.775
Recall (TPR) = 0.638
TNR = 0.940

F1 = 0.740

Very little difference between using whole casebase and only using previous cases each time

Local accuracy rates (measured for every 59 out of 294 cases):
1. 78%
2. 78%
3. 73%
4. 84%
5. 76%

No clear pattern as before, possible that positions of cases affects this







KNN with regular outcomes: 

Whole CB:

Accuracy - 86-88% by changing n, pretty much only chooses approval (not very good)

n = 3

tpcount = 251
fpcount = 35
tncount = 1
fncount = 13

n = 7 

tpcount = 260
fpcount = 36
tncount = 0
fncount = 4

n = 11
tpcount = 264
fpcount = 36
tncount = 0
fncount = 0

Using KNN with regular outcomes seems pointless as it increasing n pretty much approximates zero rule i.e choosing all as "approved"

Temporal ordered casebase:

^ similar results as before








KNN with factors as outcomes: (back addition)


Test on whole casebase (294 cases) 

k = 6 for optimal accuracy

Accuracy = 87% - better than AACBR

P = 127
N = 167
tp = 108
fp = 20
tn = 147
fn = 19

Precision (PPV) = 0.844
NPV = 0.886
Recall (TPR) = 0.857
TNR = 0.875

F1 = 0.850

Similar success using rear extension as factor, k = 8

tp = 108
fp = 17
tn = 150
fn = 19


Temporally ordered testing, only using previous cases as casebase:

k = 6
number of cases = 288 (first few cases must have previous CB entries to draw from)

Accuracy = 83%

tp = 97
fp = 18
tn = 143
fn = 30

not much difference again

Local success rates (taken for every 48 out of 288 cases):
1. 79%
2. 87%
3. 83%
4. 87%
5. 87%
6. 87%

Perhaps some pattern here - weaker at the start?







SPEED


Average per computation over 10 tests

100 case casebase:

AACBR: 0.149s
KNN: 0.000501s

200 cases:

AACBR: 0.669
KNN: 0.00102

300 cases

AACBR: 1.885s
KNN: 0.00140s

400 cases

AACBR: 4.117
KNN: 0.00170

500 cases

AACBR: 7.70
KNN: 0.00230

600 cases

AACBR: 12.7
KNN: 0.00271

700 cases

AACBR: 20.4
KNN: 0.00352

800 cases

AACBR: 30.3
KNN: 0.0038

900 cases

AACBR: 41.8
KNN: 0.00445

1000 cases

AACBR: 58.4
KNN: 0.00491


Accuracy:

KNN: Same accuracy for back addition (87%), accuracy for rear extension decreased from 88% to 80% going from 300 to 1400 cases (possibly just due to casebase)

BE: tpcount = 766
fpcount = 103
tncount = 464
fncount = 67

RE: tpcount = 607
fpcount = 149
tncount = 525
fncount = 119

